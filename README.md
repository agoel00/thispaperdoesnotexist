# This Paper Does Not Exist!

[Live](https://thispaperdoesnotexist.netlify.com)

These titles and abstracts have been generated by a fine tuned GPT-2 model.
The model has 345M parameters and has been trained on ~30k papers from arxiv.

The results are generated at a temperature=0.7

The model has learnt a lot of contextual meaning from the abstracts and the 
generated titles and abstracts are really good for a training time of just 40 minutes.

### TODO
- [x] Train on ~30k papers
- [x] Deploy on website as POC
- [ ] Train on more papers
- [ ] Upload fine-tuned weights

