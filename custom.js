var titles = [
    ['Space-time Expansions'],
    ['A New Approach to Organizing Neural Network Models to Improve Their Accuracy'],
    ['"Improving Deep Convolutional Neural Networks for 3D Object Representation"'],
    ['"The Multimodal Recurrent Network: A New Class of Fully Connected Recurrent Networks"'],
    ['"The Essence of Multi-Modal Learning: A Framework for Multi-Modal Transfer Learning"'],
    ['"Efficient and Scalable Collaborative Regularization for Ordinal Conjugate More Equal-Weighting"'],
    ['"Performing Degree Constrained Optimization for Handwritten Handwriting Recognition"'],
    ['"A Randomized Multi-Mean Network for Regularization in Fixed-Point Linear Programming"'],
    ['"Towards a new algorithm for learning an optimal distance metric for inference"'],
    ['“Importance of the Interpretation of Task Groups: An Experimental Study"'],
    ['The Effect of Variational Closest-Based Regularization on Randomization Error for Manager-Level Size Optimization'],
    ['"A uniform representation of the grammar of English grammar based on a sequence of pseudo-grammar pairs and their meanings"'],
    ['"A New Approach to Assessing the Effectiveness of Differential Learning"'],
    ['Fast, Simple and Efficient Aggregation of Multitasker Models'],
    ["We Can't Believe in the Real-World: A Study of Heterogeneous Multitasker Models"],
    ['A Large-scale Multi-Scale Shopping Listing Projection Using Anomaly Detection and Retrieval Technique'],
    ['"Learning the Differential Analysis of an Equation for Optimizing the Completion of Subspace-based Linear Combinations"'],
    ['"An Evaluation of the Partial Difference Between a Gaussian and a Gaussian-gradient-gradient"'],
    ['Augmented Response Time Algorithm'],
    ['"Optimal Self-Assessment for Automatic Specifications for Video Classification"'],
    ['"Error Loss Function Algorithms for Deep Learning with Randomized Support Vector Machines"'],
    ['"A New and Improved Approach to Detecting Non-Euclidean Structures in 3D Images"'],
    ['A new algorithm for non-Euclidean topics in 3D'],
    ['Decision Making in the Presence of Uncertainty and Performance Expectations'],
    ['"An Empirical Study of the Future State of the Art for Color Images Processing"'],
    ['"An Empirical Study of Color Image Processing – A Comparison of Colour Image Processing System"'],
    ['A Color Image Processing System for Image Classification'],
    ['Clutter-based Interactive Objects for Interactive Learning: A Preliminary Evaluation'],
    ['"Semantic Inference for Detecting and Managing Embedded Systems That Use Media"'],
    ['"Towards Universal Frequency Adaptation of Skew-Adaptive Image Classification"'],
    ['Visual Recognition by Convolutional Neural Networks'],
    ['Learning to play UASP with algorithmic trade-offs'],
    ['Semantic Segmentation of Deep Neural Networks'],
    ['"Learning to Use Stereo Images as Images for Large-Scale Learning"'],
    ['"A Linked Data Structure and Linked Features for Learning Linear Programming Languages"'],
    ['Semantic Extraction for 3D Contextual Recognition'],
    ['"Semantic Analysis and Classification Based on the Spatial Level Representation"'],
    [' "A Semi-supervised Classifier for Categorization and Image Segmentation: A New State of the Art for Image Segmentation"'],
    ['"A Generalized Nonparametric Bayesian Model for Learning and Classification"'],
    ['"A Nonparametric Bayesian Approach to Partial Bayesian Classification"']
]

var abstracts = [
    [`"Subspace Expansions (SE) are a powerful area of mathematics that is applicable in
    many areas of science, engineering, computer science, and medicine. The fundamental
    problem is to find a subspace of a space-time space where the spaces are of any
    descendant length. In general, we consider the subspace as being of any
    descendant length and it is rational to assume the subspace to be continuous. We
    present a general algorithm to find a subspace that is continuous with a
    Subspace”
    `],
    [`"We propose a new neural network model for organizing the training data from
    each component of a neural network model. Our model combines a
    combination of the best of two approaches: a global learning
    based approach and a model adaptation approach. We evaluate our
    model using a large-scale, online surgical image dataset obtained
    from the Hospital-Northeastern University Hospital Patient Registry. We show
    that our model can significantly improve the scanner-to-scanner accuracy
    of the model by up to 15% on the standard dataset."
    `],
    [`"We propose a novel deep convolutional neural network (CNN) model
    for 3D object representation. Our model incorporates an extra layer of
    convolutional neural network (CNN). Unlike the standard 2D convolutional
    neural network (CNN), we model the 3D space with a deeper convolutional
    network, which is able to process 2D images. We demonstrate that our
    model can be applied to 3D object representations and achieves the
    state-of-the-art 3D object representations on the 3D image dataset
    and the 3D correction dataset. We develop a feature extractor
    that can be used for the deep convolutional network model. Our experimental
    results demonstrate that our model achieves the state-of-the-art 3D object
    representation on both the 3D image dataset and the 3D correction dataset."
    `],
    [`"The multimodal recurrent network is a recently introduced approach to
    recurrent networks, which can be thought as a hybrid of multilinear and
    multi-level recurrent networks. The network can be thought as a
    multimodal recurrent network, and it is able to learn complex
    nonlinearities such as the inverse normalized logarithmic ratio. As the
    network is multilinear, it is able to learn nonlinearities that are
    dependency-free and dependent on only a single input. Moreover, the
    network is able to learn complex nonlinearities that are to some extent
    relaxed, and it can be thought as a multi-level recurrent network. The
    network can be thought as a multilinear recurrent network. The network is
    multimodal in that the inputs are of any class, and it inherits
    features such as the inverse normalized logarithmic ratio. The network is
    multi-level in that the input is of any class, and it can be thought as a
    multi-level recurrent network. The network is an iterative recurrent network
    where the inputs are of any class, and it inherits features such as the
    iterate norm. We evaluate the multicore-based for the multicore-based
    multimodal recurrent network on a subset of synthetic and real data sets. We
    obtain the best performance on synthetic and real data sets."
    `],
    [`"We propose a framework for multi-modal transfer learning, which
    utilizes the techniques of multi-modal transfer learning and a class of
    distributed neural networks. We show that our framework has improved the
    transfer learning performance of the classical multi-modal transfer learning
    System”
    `],
    [`"Ordinal conjugate weighting (OBW) is a popular unsupervised and
    computationally efficient procedure for multi-class classification that works well
    for both categorical and multi-dimensional data. However, the
    performance of OBW for the multi-class classification task suffers from
    attribute noise in the data. We propose a novel unsupervised and
    computationally efficient multi-class OBW algorithm, which seeks to minimize
    the variance of the weighting over multiple sets of class labels in the
    data. The proposed algorithm is the first unsupervised OBW algorithm to
    maximize the variance of the weighting over multiple sets of labels
    in the data. We demonstrate the effectiveness of the proposed algorithm
    on a multi-task multi-label classification task and also on an unsupervised
    multi-class classification task using real-world datasets."
    `],
    [`"Handwritten handwriting recognition has become a popular yet challenging
    problem. The application of high quality handwriting recognition
    techniques is very important in many fields like game development,
    robotic self-driving vehicles, and other applications. The global handwriting
    recognition market is worth over US$US$2 billion. The standard algorithm is
    Performative Gradient Descent (PGD)-based.”
    `],
    [`"Fixed-point linear programming (FPL) is a widely used paradigm for
    the design of finite-dimensional linear programming (FPL). The FPL
    algorithms are simple enough and powerful enough to be used in many
    real world applications. However, their simplicity and power
    deprive FPL algorithms from their practical application. In this paper,
    we introduce a new FPL algorithm, Randomized Multi-Mean Network (RMN),
    which is designed to be easier to use, simpler to implement, and faster to
    compute. Our RMN requires the use of fixed-point linear programming (FPL)
    and is fast to compile. We also show that our RMN can be used to
    better optimize the FPL algorithm. The RMN is designed to be easy to use and
    fast to compute. We present experimental results on four benchmark
    datasets to demonstrate the effectiveness of our RMN algorithm."
    `],
    [`"We propose a new algorithm for inferring a distance metric from a
    recurrent neural network (RNN) training set. In our experiments,
    the proposed algorithm outperforms the state-of-the-art algorithms in
    two performance measures for inference tasks. We show that the
    probabilistic approach is capable of inferring a distance metric that
    is close to the optimal distance metric. Our results are compared to
    the state-of-the-art techniques that use a variational algorithm.
    `],
    [`"This paper presents a study to investigate the use of the
    interpretation of task groups in learning multiple language models
    from a single image. The task groups are the input images and the target images,
    both of which are quite different in their semantic domains. In this way,
    the task groups can be used to teach two language models to each other. To
    examine the use of the task groups, we have constructed a framework
    for extracting and comparing task groups. We show that the reference task
    groups correspond to the best known task groups extracted from a
    traditional image-based language model, and that our framework performs
    better than the reference task groups."
    `],
    [`"We study the effect of variational regularization and randomization
    in the size of the manager for the manager-level size optimization.
    The method for the size of the manager is 2-step: We first consider a
    large-scale manager to be a monotone sequence, and then assume a
    deterministic sample of the managers and a random sequence. A
    deterministic sample is a sequence of the managers and a random sequence
    is the random sequence. We prove that the size of the manager is dependent on
    the size of the random sequence and the size of the manager in the
    deterministic sample. Then we apply the method to the manager-level set
    of managers, and show that the size of the manager can be improved by
    considering a small-scale manager. The method is guaranteed to converge to the
    correct size of the manager if the random sequence and the size of the
    manager are the same. The method is also guaranteed to converge to the
    correct size of the manager if the random sequence and the size of the
    manager are different."
    `],
    [`"This paper presents a uniform representation of the grammar of
    English grammar based on a sequence of pseudo-grammar pairs. The
    representation is based on a set of pseudo-grammar pairs and consists of 8
    pseudo-grammatical stages: grammatical, lexical, propositional, modal
    `],
    [`"We review the recent work on differential learning, which has led to many
    improvements in classification performance in a variety of applications.
    We also provide an overview of recent work in the field, and provide
    a brief discussion of the motivation behind differential learning."
    `],
    [`"The multipacket representation of a multitasker model
    is a simple, fast and robust data representation. Recently, multitasker
    models have been developed for many tasks and different language
    subtasks. The multipacket representation is a simple and fast data
    representation. For example, in multitasker modeling, the multipacket
    representation is used for multi-task learning and classification. In
    this paper, we propose a simple and efficient multipacket representation
    for multitasker modeling. We use the multipacket representation to
    learn a multitasker model of a single task. We propose a simple
    alternating method for multipacket learning, which is based on the
    multipacket representation. Our method learn a new multipacket model.
    Experimental results show that our method achieves competitive performance
    on different data sets and different tasks."
    `],
    [`"The recent rapid development in multitasker data for several
    tasks, such as graph-searching, is not confined to a single task.
    For example, there are multitasker models for many real-world tasks,
    such as medical diagnosis, shopping and online network administration.
    The recent rapid development in multitasker data is not confined to a
    single task. The recent rapid development in multitasker data for
    multitasker modeling is not confined to a single task. We aim to
    uncover the heterogeneous data sets and the heterogeneous data types,
    and to develop a publicly available multi-task task-specific multitasker
    model for each task. The heterogeneous data set is heterogeneous
    multitasker data sets that consist of multiple types of data, including
    Sears catalogs, Sports Illustrated”
    `],
    [`"We present a novel anomaly detection and retrieval (A2R) system with
    multi-scale features in a multi-scale shopping listing system. We show that
    the system can be easily extended to a new multi-scale system with larger
    evaluation space on a single, multi-scale listing instance. The system
    can be used on a shopping listing system where an arbitrary number of shoppers are
    presented to the system. We present alternative A2R methods that enhance the
    performance of the new system, and the results demonstrate that the old
    system can be easily extended to a new multi-scale system with larger
    evaluation space on a single, multi-scale listing instance."
    `],
    [`"In this paper, we consider the optimization of a single linear combination
    by means of a subspace-based linear combination. This subspace
    is defined by the class of subspaces of the linear combination. In this
    paper, we first describe the notion of a subspace-based linear combination,
    and then give an analysis of the differential analysis of an equation of
    the subspace. We also consider a generalization of this approach which
    uses the data of a finite class of subsets of the linear combination.
    Moreover, we demonstrate how we can solve the optimization problem
    with a subspace-based linear combination and generate a rigorous proof for
    the subspace-based linear combination. We then describe our proposed
    approach in detail, discussing the properties of the subspace, the
    problem of subspace-based linear combination and the optimization of
    a linear combination with subspace-based linear combination."
    `],
    [`"We consider the partial difference between a Gaussian and a Gaussian-gradient
    gradient. The original gradient is defined as a function with the
    gradient distributed on the gradient vector. We evaluate the gradient on a
    Gaussian-gradient of a Gaussian-gradient of a regressor.”
    `],
    [`"In the current state-of-the-art response time algorithm, the
    model-based approach is preferred because it allows to solve the
    theoretically simple problem of estimating the target time for a user
    application. However, the model-based method is known to be susceptible of
    stability problems due to the spread over multiple users. Here, we
    propose a novel method for model-based response time estimation that
    combines a novel set of algorithms and a novel model-based representation
    for the target time. Our model-based set of algorithms is modeled as a
    combination of a class of convolutional neural networks (CNN) and a
    generalization of the convolutional neural network (CNN). We first show how
    to construct a model-based ensemble of convolutional networks (CNN) and
    a generalization of the convolutional neural network (CNN). Then, we analyze the
    effect of the model-based ensemble on the response time estimation.
    Finally, we show how the model-based ensemble can be used to guide the
    procedure of convolutional networks"
    `],
    [`"Public sector video surveillance is a demanding and challenging task for
    its widespread use. In this paper, we present a novel video classification
    system. The system is able to automatically enable both passive and active
    video surveillance, and is able to classify videos based on the
    automaticality and efficiency. The system conducts a video (including the
    intersection) analysis for the classification and then executes the
    video classification. The system is tested on a new dataset from the
    European Commission, which contains videos taken by a member of the European
    Commission. The system was able to classify videos of different types and
    level of realism. The system is compared with the state-of-the-art
    video classification system."
    `],
    [`"We introduce the Error Loss Function Algorithms (ELF) for deep
    learning. We propose to use only the inputs to the embedding and the
    outputs to the network, rather than based on a global optimization
    procedure. Our algorithm uses hidden state space as the input to the
    embedding and global optimization to the network.
    `],
    [`"Non-Euclidean structures have been widely studied for decades.
    However, the non-Euclidean structures in 3D images pose a wide variety of
    challenges. In this paper, we propose a novel and effective algorithm
    for detecting non-Euclidean structures in 3D images. Our algorithm is based
    on the linear transformation from a 3D point cloud to a 2D vector, and
    uses a novel convolutional neural network architecture to produce a
    non-Euclidean structure that is accurate at detecting non-Euclidean structures
    in 3D images. Our algorithm is a powerful and flexible way to tackle
    complex non-Euclidean structures in 3D images. Our experimental results on a
    variety of 3D images show that our algorithm is capable of detecting
    non-Euclidean structures in 3D images and outperforming state-of-the-art methods
    in both detecting and predicting them."
    `],
    [`"Non-Euclidean topics are topics that are related to Euclidean
    objects. They are a rich source of information for the study of
    semicircular geometry. In this paper, we introduce a new algorithm
    for non-Euclidean topics. The algorithm is based on the linear
    transform from a 3D point cloud to the 2D vector. The algorithm is a
    new kind of non-Euclidean topic that can be used in the study of geometry.
    We have tested our algorithm on the task of Euclidean topics
    `],
    [`"We consider the task of deciding whether to make a decision in the presence of a
    high degree of uncertainty and performance expectations. In particular,
    we consider the task of choosing whether to maximize the probability that the
    performance values computed by the user are maximally close to the
    best possible. We consider a variety of approaches to the problem of
    deciding whether to maximize the probability that the user's behavior is optimal.
    We analyze both stochastic and random sampling, and propose a
    new algorithm, Decision Making in the Presence of Uncertainty and Performance
    Empirical Evidence, which is equivalent to an implementation of Decision Making
    with a simple but powerful back-propagation algorithm. We demonstrate that our
    decision making algorithm is competitive with state-of-the-art
    decision making approaches, such as the Decision Making Framework."
    `],
    [`"This paper presents a comprehensive study of the performance of color image
    processing algorithms in terms of image quality and image size. The
    paper presents a comprehensive study of the performance of color image
    processing algorithms in terms of image quality and image size. The
    performance of color image processing algorithms have been shown to
    be the best performing color image processing algorithms in the worlds of
    image and color. In contrast, the color image processing algorithms have not been
    shown to be the best performing color image processing algorithm in
    the world of color."
    `],
    [`"This paper presents a comprehensive study of color image processing
    systems. The paper presents a comprehensive study of color image
    processing systems. The color image processing systems have been shown to be
    the best performing color image processing
    systems in the worlds of color and color. In contrast, the color
    image processing systems have not been shown to be the best performing
    color image processing system in the world of color."
    `],
    [`"From a colour image representation literature, we propose a new color
    image processing system, based on the color image representation. We
    propose a colour image representation method that is based
    on the color image representation method. The proposed method uses two
    color image representations
    `],
    [`"In this paper, we present an interactive learning method for interactive
    learning consisting of a simple procedural exploration of a small set of interactive
    objects. We first introduce the concept of interactive objects, which can
    be viewed as a collection of interactive objects that can be added or removed
    from a scene. Our reasoning is that these interactive objects can be
    used for learning learning, and the first step in learning is to
    activate a set of interactive objects. Then, we propose a novel
    interactive object learning framework that is designed to be flexible and
    useful in different contexts. We conduct a preliminary evaluation to
    illustrate the effectiveness of our approach in interactive learning."
    `],
    [`"Embedded systems that use media are not immune to problems. In this
    paper, we introduce a semantically accurate embedded system that uses media
    to detect embedded systems that use media. Our system uses media
    according to a semantic model that is trained on the images captured by
    embeddings with built-in semantic models. It uses semantic models from the
    media, such as image tags. The result is a semantically accurate
    `],
    [`"Skew-adaptive image classification is a popular class of image
    classification models. However, the model is often formulated to exploit
    the joint distribution of image and frame-level (e.g., Caltech-Boltzmann
    box) distributions. This method has been shown to be effective, yet it
    lacks the capacity to handle most common image types such as JPEG. To address
    this problem, we develop a new method, based on Skew-Adaptive Image Classification
    (SAC) to build a single-image classifier that can address all image types.
    SAC is a method that exploits only the joint distribution of the image
    and frame-level distributions, thus avoiding the joint distribution of the
    image and frame-level distributions. Our new method is tested on a range of image
    datasets and achieves competitive results over the existing state-of-the-art
    semi-supervised image classification models. Furthermore, we demonstrate the
    effectiveness of our approach by comparing it to state-of-the-art semi-supervised
    image classifiers on three challenging video datasets."
    `],
    [`"Several recent visual recognition methods have been proposed. However,
    their main contribution has been the use of convolutional neural networks.
    However, the output from the convolutional neural networks are often used for
    visual recognition. In this paper, we propose a new convolutional neural network
    model for visual recognition. This model is based on a convolutional convolution
    network with a convolutional recurrent network network. It works on both
    epipolar and polar orientations and has a convolutional filter that intercepts the
    neighborhoods in the image. The same model is also applied to image
    recognition. Experiments on two benchmark datasets indicate the effectiveness of
    the proposed model."
    `],
    [`"The goal of this paper is to provide a unified view of the
    algorithmic trade-offs that make UASP so effective. We present a
    new algorithm for UASP that is designed to maximize the experiment loss while
    being able to use UASP as a learning tool in the presence of computational
    errors. The learning problem is simple: One can define a random set of
    pixels that represent each pixel of the image. In this paper, we use a
    different algorithm for the learning task. We show that our algorithm
    outperforms existing UASP algorithms on this task. Our algorithm also
    demonstrates exceptional performance on a variety of different benchmark
    datasets with the best results on a benchmark image-based database."
    `],
    [`"Deep neural networks (DNNs) have achieved states of the art performance
    in deep convolutions, which are a class of convolutional neural networks (CNNs).
    Because of their highly effective image-level segmentation, DNNs have been widely
    used in many applications such as semantic segmentation. However,
    this class of networks is not well-suited for semantic segmentation. In this
    paper, we propose a new kernel-based mechanism for semantic segmentation
    based on the 2D convolution network and the 3D convolution network. Our
    proposed method requires only a single input image and achieves state-of-the-art
    semantic segmentation accuracy on a classification benchmark. The proposed
    semantic segmentation method is based on the convolutional network and the
    3D convolution network, which are both known to be effective for semantic
    segmentation. The proposed method can be applied to any DNN and achieves
    state-of-the-art segmentation accuracy on a variety of semantic datasets."
    `],
    [`"Learning a large-scale hierarchical model such as the Sparse Markov Random Field
    (SMF) remains challenging for adversarial learning. In this paper, we
    present an approach that exploits the features of multiple subsets of
    the model space and learn a hierarchical model for large-scale learning
    using a sparse matrix of the input image.
    `],
    [`"A number of linguistic and mathematical methods have been proposed to
    learn linear programming languages. Most of these methods, notably
    LSTMs, are based on the idea that a language is a set of raw
    data; the data structure, or linked data structure, is a collection of
    as many data points as possible. This idea is valid for the
    language theory; for instance, it is valid for the historical linguistics.
    However, there are two main problems with this view: 1) The
    methods seem to be applicable only to the language theoretic
    language, and 2) The methods are not applicable to all languages. We
    introduce a new algorithm, called Linked Data Structure and Linked
    Features (LDS), which is based on the idea that a language is a
    collection of data points. The algorithm is designed to work on the
    language theoretic language. It is designed to work on languages which
    have already been studied in the historical linguistics.
    `],
    [`"3D context-aware 3D semantic segmentation is a challenging problem in many
    application domains. This paper proposes a novel 3D semantic segmentation
    method known as Semantic Extraction (SE). SE is an automatic semantic
    extraction algorithm with a novel semantic segmentation strategy. Based on the
    semantic data captured by a 3D camera, SE estimates the 3D semantic
    2D context with a 2D semantic segmentation algorithm. This paper adopts a
    simple but effective approach to semantic segmentation for 3D images.
    SE is tested on two benchmark 3D image datasets and compared to the
    state-of-the-art semantic segmentation algorithms. We demonstrate that SE
    is able to learn semantic segmentations that are more accurate than
    current state-of-the-art semantic segmentation algorithms, and is able to
    achieve superior performance in semantic segmentation for 3D images."
    `],
    [`"In this paper, we present an automatic 3D semantic segmentation
    method based on the spatial level representation of the 3D image.
    The 3D semantic level representation of a 3D image can be a 3D
    translation pattern or a 3D semantic segmentation pattern. Extensive
    experiments on three 3D semantic segmentation datasets show that the
    semantic level representation can be useful for semantic segmentation
    and can be useful for semantic segmentation."
    `],
    [`"Image segmentation is a fundamental task in computer vision. Image
    segmentation systems have been extensively studied over the last years. In this
    paper, we introduce a new image segmentation system, which is based on a
    state-of-the-art image segmentation systems which has been developed
    over the last decade. This paper presents a semi-supervised Classifier for
    segmentation and image segmentation and a new state-of-the-art image
    segmentation system, which was developed for the purpose. The proposed
    segmentation and image segmentation systems were designed to perform
    segmentation from sparsely sampled images with two data points,
    and were evaluated on a set of images of Turkish image. The aim of our
    development is two-fold: first, we propose a new classifier for image
    segmentation which is based on a state-of-the-art image segmentation
    system, and second, we propose a new image segmentation system based on a
    state-of-the-art image segmentation system, which was developed over the last
    decade. We evaluated our proposed implementations on several standard
    segmentation datasets”
    `],
    [`"We consider a framework for learning and classification of action
    variations, using a Bayesian framework. Using a conditional
    presumption on the distribution of information, we learn a nonparametric
    Bayesian model with a variational inference-based variational Bayesian
    model. We show that the variational Bayesian model can be applied to the
    real world: it can be used to help identify information in a noisy
    environment, and to generalize the variational Bayesian model to nonparametric
    Bayesian-based models. As our framework is simple and easy to implement,
    it is easy to learn and to use. We show that the variational Bayesian
    model can be used to learn and classify more complex and dynamic
    variations of action types."
    `],
    [`"We present a new nonparametric Bayesian model for partial Bayesian
    classification. Using a variational inference-based variational
    Bayesian model, we train an unsupervised variational Bayesian model, generating
    the latent variables, and then using the latent variables to model the
    position of the latent variables. The latent variables serve as
    reference-variables, which are used to model the latent variables and the
    inference. The latent variables are inferred from the latent variables,
    and used to define a random variable, which are used to predict the
    variance of the latent variables. Our model is trained on the
    across-the-synthetic- and real-world data sets, and is evaluated on a
    collection of synthetic and real-world data sets. The experimental
    results on synthetic and real-world data-sets demonstrate the effectiveness
    of our model, and its ability to generalize to more complex
    living environments."
    `]
]

// var heading = document.querySelector('#title');
// heading.innerHTML = titles[Math.floor(Math.random()*10)];
// heading.innerHTML = abstracts[0];
console.log(titles[Math.floor(Math.random()*10)]);
// console.log(Math.floor(Math.random()*10))

let btn = document.querySelector('#btn');
let heading = document.querySelector('#title')
let abs = document.querySelector('#abstract')

let num = Math.floor(Math.random()*10);
heading.innerHTML = titles[num]
abs.innerHTML = abstracts[num]

function refresh()
{
    let num = Math.floor(Math.random()*10);
    heading.innerHTML = titles[num]
    abs.innerHTML = abstracts[num]
}