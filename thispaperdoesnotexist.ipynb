{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thispaperdoesnotexist.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K07XdnaOqTUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT6Bf_KgqfMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json('arxivData.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqs6oC9pqje_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data = df[['title', 'summary']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvM1cUQPqpS0",
        "colab_type": "code",
        "outputId": "be779c07-202a-4567-e878-96c40a885432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqUwe6v2lXOY",
        "colab_type": "code",
        "outputId": "01b34fb4-b9db-478f-951b-b07bbe160c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.iloc[:30000].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoGRft-ZliAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_data = data.iloc[:30000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tYXgQtuq-B7",
        "colab_type": "code",
        "outputId": "98ecbed8-06d4-480c-ea8a-6b7efde96994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "\n",
        "!pip install -q gpt_2_simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7SWi4tYrVUa",
        "colab_type": "code",
        "outputId": "5c65d67f-d2e3-4063-9e56-8d6e85bba270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May  9 18:23:45 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_ooG00PsCGQ",
        "colab_type": "code",
        "outputId": "f1b47caa-21ad-476f-89ba-8b1f854d23c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"345M\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 192kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 43.2Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 317kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:22, 62.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 2.71Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 40.8Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 27.1Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpkZLxEqsJTC",
        "colab_type": "code",
        "outputId": "2a32c920-938c-46a7-ce9d-003d4b940e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "345M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwz24HmksXHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_data.to_csv('train_data.txt', header=None, index=None, sep='\\n', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi0TuMNBsrEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! cat train_data.txt\n",
        "!sed -n 1,80p train_data.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-4_Meoqsswn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'train_data.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtH5KuNCfjCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCd5TLlYh43g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agPL1hqPtgYg",
        "colab_type": "code",
        "outputId": "b1946cf6-6974-4743-a512-275d98681968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6939
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "             dataset=filename,\n",
        "             model_name='345M',\n",
        "             steps=1000,\n",
        "             restore_from='fresh',\n",
        "             print_every=10,\n",
        "             sample_every=200,\n",
        "             save_every=500\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Loading checkpoint models/345M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [01:58<00:00, 118.58s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 20717505 tokens\n",
            "Training...\n",
            "[10 | 24.49] loss=3.35 avg=3.35\n",
            "[20 | 39.70] loss=3.31 avg=3.33\n",
            "[30 | 55.11] loss=3.28 avg=3.31\n",
            "[40 | 70.70] loss=3.22 avg=3.29\n",
            "[50 | 86.52] loss=3.17 avg=3.26\n",
            "[60 | 102.43] loss=3.11 avg=3.24\n",
            "[70 | 118.57] loss=3.30 avg=3.25\n",
            "[80 | 135.17] loss=2.90 avg=3.20\n",
            "[90 | 151.72] loss=3.00 avg=3.18\n",
            "[100 | 168.05] loss=2.79 avg=3.14\n",
            "[110 | 184.26] loss=3.30 avg=3.15\n",
            "[120 | 200.50] loss=3.16 avg=3.15\n",
            "[130 | 216.85] loss=3.05 avg=3.14\n",
            "[140 | 233.26] loss=2.99 avg=3.13\n",
            "[150 | 249.61] loss=2.99 avg=3.12\n",
            "[160 | 265.95] loss=3.00 avg=3.11\n",
            "[170 | 282.29] loss=2.90 avg=3.10\n",
            "[180 | 298.62] loss=2.98 avg=3.09\n",
            "[190 | 314.96] loss=2.99 avg=3.09\n",
            "[200 | 331.28] loss=2.95 avg=3.08\n",
            "======== SAMPLE 1 ========\n",
            " From the beginning, the main reason we chose to conduct the simulation using these parameters was the uncertainty in the\n",
            "simulation model that we considered for the number of parameter parameters in the\n",
            "approximation. Our first parameter was the \"number of parameters\" from the\n",
            "beginning with a fixed number of parameters. In this case, the simulation\n",
            "model itself can be used to model uncertainty in its parameters without\n",
            "having to worry about parameter noise. Our second parameter was the \"parameters\n",
            "in the simulation\" from the end. This was chosen because of the degree to which\n",
            "the model can be used in general applications when only limited parameters\n",
            "are used. Our final parameter, from the beginning with only a few parameters as\n",
            "the number of a parameter, was chosen based on the fact that it represents an\n",
            "exact number from the beginning of the simulation. It was chosen because the uncertainty of\n",
            "the parameter could be simulated in any reasonable range using the simulation\n",
            "model, and we can easily find the number of parameters without the need for\n",
            "constraint.<|endoftext|>The United States has a long history of supporting, and encouraging, trade between Latin American countries such as Peru, Bolivia, and Chile that are not\n",
            "closely in trading partner, as well as in other Latin American countries such as Ecuador. It is time to change that, and\n",
            "we are proposing a new multilateral framework that involves a multilateral investment guarantee\n",
            "and a policy of reciprocal protection of the investment guarantees, with\n",
            "the explicit intention of expanding the protection to allow more than one investment\n",
            "per country within the framework of their trade agreement.\n",
            "This research, under the auspices of the Council for Foreign Relations, is to examine the implications of\n",
            "this, as well as the possibilities of changing Latin American trade agreements to benefit Latin America. The papers address\n",
            "two main categories of Latin American trade partners. First, Latin American countries are in\n",
            "significant financial problems, yet are more than willing to work with each other. Second, a common\n",
            "opposition to an investment guarantee might serve to provide a means for a certain\n",
            "Latin American country to withdraw from these problems if necessary, thus strengthening its position. In fact, the\n",
            "evidence is that both such options are possible, and both are likely with the most conservative\n",
            "approach. We present a detailed discussion of the possibilities, and provide a general framework that\n",
            "can be used to design multilateral investment commitments in addition to bilateral ones.\"\n",
            "Corporate Social Responsibility: A Comparative Perspective\n",
            "\"This study considers the fundamental challenge of corporate social responsibility. We present\n",
            "a comparison between a standard definition of such responsibility in the law and its\n",
            "underlying understanding, and current theoretical reflection and policy.\n",
            "Rather than focusing on the social costs of corporate social responsibility, we argue\n",
            "that it is the individual responsibility to contribute to the creation of a better corporate\n",
            "business. On the basis of that, we explore whether the law allows for a meaningful analysis of \"\n",
            "corporate social responsibility within its own scope.\"\n",
            "Sustainability and Energy Independence: A Brief Case Study\n",
            "\"In this paper, we present a brief case study on sustainability, especially in relation to the\n",
            "energy source in question. First, we consider the problem of energy demand, and note the consequences that\n",
            "energy supply, especially on the global energy supply, now poses in terms of the\n",
            "physical environment, and how that changes with climate change and the global energy security. Secondly\n",
            "we describe an interesting example where natural gas prices are very low and are\n",
            "still cheaper than coal in the US. We briefly discuss several alternative energy alternatives and an\n",
            "analysis of the implications of an energy security analysis. Thirdly, we briefly discuss an\n",
            "unconventional renewable energy energy source, and its role in the energy and climate\n",
            "change security. As an illustration, we use that source to illustrate how the renewable resource\n",
            "possesses an edge over the coal-fired power plants in its potential range. And, we briefly look at the\n",
            "cost of electricity generated from wind power, and its implications for energy security.\"\n",
            "Neptune Revisited: A Review and Introduction To Jupiter\n",
            "\"Our recent study of the Jupiter system reveals the presence of moons, and that a\n",
            "super-Earth has occurred on Jupiter itself. It is therefore no surprise to learn that the\n",
            "habitable climate on Jupiter is very similar to the ones in the moon KIC 8462855. A\n",
            "review of these planets with reference to the Moon and its moons is provided in this article.\"\n",
            "\"How to Make an Open Data Model for Big Data for Open Development and the\n",
            "  Future\"\n",
            "\"The data of a system is the information of a program or component that it controls, and\n",
            "tasks to be analyzed. It is a collection of data generated by the system; and\n",
            "this collection could be generated on a wide range of platforms. The process of using\n",
            "that data to formulate new systems is described here in terms of how many possibilities\n",
            "and ways of doing so in which the data can be analyzed\n",
            "\n",
            "[210 | 373.99] loss=3.08 avg=3.08\n",
            "[220 | 390.37] loss=3.11 avg=3.08\n",
            "[230 | 406.74] loss=3.04 avg=3.08\n",
            "[240 | 423.13] loss=2.81 avg=3.07\n",
            "[250 | 439.51] loss=3.13 avg=3.07\n",
            "[260 | 455.94] loss=2.84 avg=3.06\n",
            "[270 | 472.33] loss=2.93 avg=3.05\n",
            "[280 | 488.73] loss=2.98 avg=3.05\n",
            "[290 | 505.12] loss=2.83 avg=3.04\n",
            "[300 | 521.53] loss=2.90 avg=3.04\n",
            "[310 | 537.95] loss=3.14 avg=3.04\n",
            "[320 | 554.35] loss=3.00 avg=3.04\n",
            "[330 | 570.75] loss=3.18 avg=3.04\n",
            "[340 | 587.14] loss=2.81 avg=3.04\n",
            "[350 | 603.55] loss=2.95 avg=3.03\n",
            "[360 | 619.96] loss=3.12 avg=3.04\n",
            "[370 | 636.38] loss=2.85 avg=3.03\n",
            "[380 | 652.80] loss=2.99 avg=3.03\n",
            "[390 | 669.21] loss=2.79 avg=3.02\n",
            "[400 | 685.62] loss=2.93 avg=3.02\n",
            "======== SAMPLE 1 ========\n",
            "s as an example of when\n",
            "the system's \"keyword processing is the best option\".\n",
            "  The keyword processor in this study uses a word association service to automatically\n",
            "identify the correct key words, is tested on 15-item standard\n",
            "keyword-search (SKS), and is then evaluated on an additional SKS for\n",
            "personalized sentence retrieval (S3RD). The evaluation of the keyword\n",
            "processors in this study is complemented by comparisons with\n",
            "other key-word processing systems on a variety of public and\n",
            "non-public datasets at the University of Pennsylvania.\"\n",
            "\"A Key-to-Key Approach for Semantic Parsing\"\n",
            "\"Tackling the problem of semantic parsing of text in which words\n",
            "have specific meanings (e.g., \"to\" and \"that\" in sentence \"that\") is\n",
            "particularly difficult. A key-to-key approach has emerged recently for\n",
            "semantic parsing of words (see, e.g., Kullauer-Levy and Schmuell 2009,\n",
            "where we show that key-to-key learning from words is competitive with a\n",
            "multi-level semantic-semantics approach). While the multi-level\n",
            "semantics approach involves integrating both the meanings of words from\n",
            "text-based and word-based semantic-semantics approaches, it is difficult to\n",
            "adaptively learn the appropriate level of semantic-semantics\n",
            "procedure for a word from a given text. We present a general key-to-key\n",
            "learning approach that is capable of automatically identifying an\n",
            "appropriate text-based and word-based semantic-semantics\n",
            "relations by taking word-based knowledge as input. Our key-to-key\n",
            "results are comparable to those of the multi-level semantic\n",
            "semantics that uses the word association service as input, while being\n",
            "more flexible in its training procedure with respect to the\n",
            "language used.\"\n",
            "\"Modelling the power of social learning in language: A case study with\n",
            "  text and videos\"\n",
            "\"The main task for the Language Research Laboratory is to use research knowledge\n",
            "into the potential influence of social skills and social-related\n",
            "information. It is also the main objective of this paper to investigate the\n",
            "power of social learning in the natural language of video\n",
            "sentences. We investigate the influence of social learning on\n",
            "the power of natural language in two case studies - in order to\n",
            "identify whether some sentences contain grammatical words that\n",
            "cannot be identified using normal sentences. The first case shows the\n",
            "effective influence of social learning in identifying sentences, while<|endoftext|>\"This paper evaluates the effects of using a statistical package known as a linear model for the\n",
            "learning of the stochastic, non-convex polynomial density distribution in an\n",
            "empirical context. We show that the model produces much better performance than the\n",
            "state-of-the-art, by using it for learning different stochastic non-convex\n",
            "non-convex distributions.\"\n",
            "\"The use of linear models for the evaluation of\n",
            "  stochastic non-convex distributions\"\n",
            "\"This paper presents an implementation of linear models for the evaluation of\n",
            "solutions of the non-convex stochastic distribution. It employs a\n",
            "number of non-convex functions over which the solutions can be calculated\n",
            "accordingly. We first consider a stochastic function over the data collection stochastic\n",
            "neighborhood. Then we study the stochastic-distribution of that problem as an\n",
            "instance. In this case, both the random distribution and the stochastic-distribution\n",
            "of the stochastic-neighborhood are treated as the stochastic functions. These two\n",
            "practices are analyzed in a series of experiments. We demonstrate that the\n",
            "random distribution of stochastic-neighborhood is indeed much more likely to be\n",
            "convex than the general distribution of non-convex stochastic\n",
            "neighborhood.\"\n",
            "\"Modeling non-convex stochastic distribution\"\n",
            "\"In this paper, a stochastic-distribution of the non-convex is model of the\n",
            "stochastic-non-convex distribution. In this example the local\n",
            "variation of its non-convex stochastic distribution is studied. It is found out that\n",
            "the local variance of the local stochastic distribution can be minimized using the\n",
            "random-distribution. Further, the distribution of the random distribution\n",
            "is obtained for other stochastic non-convex stochastic-distributions.\"\n",
            "\"Stochastic Non-Convex Distribution with Nonsmooth Distribution for\n",
            "  Data Collection\"\n",
            "\"Stochastic non-convex distributions have been shown to be very interesting in the\n",
            "solutions of the non-convex stochastic distribution in the case of\n",
            "data collection problems. One problem where the stoch\n",
            "\n",
            "[410 | 724.71] loss=3.18 avg=3.02\n",
            "[420 | 741.02] loss=3.33 avg=3.03\n",
            "[430 | 757.37] loss=2.93 avg=3.03\n",
            "[440 | 773.76] loss=3.00 avg=3.03\n",
            "[450 | 790.19] loss=2.81 avg=3.02\n",
            "[460 | 806.58] loss=3.00 avg=3.02\n",
            "[470 | 822.97] loss=3.07 avg=3.02\n",
            "[480 | 839.37] loss=2.57 avg=3.01\n",
            "[490 | 855.76] loss=3.20 avg=3.02\n",
            "[500 | 872.15] loss=2.67 avg=3.01\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 900.52] loss=3.01 avg=3.01\n",
            "[520 | 917.38] loss=3.03 avg=3.01\n",
            "[530 | 933.99] loss=2.82 avg=3.00\n",
            "[540 | 950.29] loss=3.08 avg=3.01\n",
            "[550 | 966.51] loss=3.05 avg=3.01\n",
            "[560 | 982.79] loss=2.59 avg=3.00\n",
            "[570 | 999.21] loss=3.07 avg=3.00\n",
            "[580 | 1015.65] loss=2.80 avg=2.99\n",
            "[590 | 1032.03] loss=2.84 avg=2.99\n",
            "[600 | 1048.38] loss=2.92 avg=2.99\n",
            "======== SAMPLE 1 ========\n",
            "images.\n",
            "Both tasks are important for developing and improving the current\n",
            "attention model for image acquisition and display. Given both data and control\n",
            "sets, one can train a perceptually-guided approach that can both achieve a\n",
            "satisfaction and maximize the amount of temporal complexity while\n",
            "learning a robust model that is efficient while avoiding excessive\n",
            "time complexity (e.g. overfitting). In this paper, we are able to address\n",
            "these two problems by combining the best features from the image,\n",
            "classification, and training datasets, to allow a new learning task:\n",
            "combining different representations from different architectures.\n",
            "This approach also further explores the use of features from two architectures\n",
            "to enable a more flexible representation to perform simultaneous\n",
            "learning of different tasks.\"\n",
            "The Learning of Image Contour Networks from 3D\n",
            "\"We propose a probabilistic model for neural network shape learning which gives\n",
            "a new perspective on the problem of contour estimation in 3D. Our model allows\n",
            "the learning of contour networks from 3D points in 3D, a class which we refer\n",
            "to as the contour dimension. In our experiments, we show that our model is\n",
            "possible to incorporate both visual and acoustic information. The trained\n",
            "contour network uses two features: the visual feature and the acoustic feature\n",
            "from both models as reference. This allows for an intuitive view of the problem of\n",
            "contour and is the basis for visual contours used for object detection. The\n",
            "proposed approach also makes use of the visual contours in shape training. We demonstrate\n",
            "results using the existing approach of combining both visual and acoustic\n",
            "features. Our model is able to produce contour networks from both visual and acoustic\n",
            "features, yielding both visually appealing and visually informative contours.\"\n",
            "The Embedded-to-Deep Learning\n",
            "\"In the past few years, deep neural networks have been applied in many\n",
            "applications, ranging from deep neural networks to recurrent neural networks. Deep\n",
            "neural networks have provided impressive performance when tasks of large scale and\n",
            "computational complexity (including image classification, scene recognition, and object\n",
            "extraction) are combined with deep architectures. But, when it comes to the more\n",
            "complex tasks involving low dimensional data, there have been efforts\n",
            "to develop and improve on deep architectures that can work for high dimension data.\n",
            "In this work, we introduce the Embedded-to-Deep Learning (ED-DL) approach that\n",
            "uses a deep reinforcement network to learn new deep architectures that can combine\n",
            "the performance of deep architectures with that of existing deep architectures. To\n",
            "improve the performance of ED-DL, we have developed a novel\n",
            "convolutional embedding system that is able to incorporate the features of\n",
            "an existing deep architecture with those of a deeper reinforcement network in\n",
            "order to fuse the best of both worlds. We also demonstrate the effectiveness of\n",
            "ED-DL on several synthetic and real time datasets, which will be instrumental for further\n",
            "extensive research.\"\n",
            "Using Discriminating Neural Networks\n",
            "\"Deep neural networks, which have been successful in object recognition,\n",
            "preserving high level of detail in high spatial resolutions, are being used\n",
            "for a variety of real-world tasks. In this paper, we present a method to\n",
            "use deep hierarchical deep networks to discriminate high resolution\n",
            "object images into low resolution and high resolution versions. We validate the\n",
            "proposed method on image classification problems, using a dataset available at\n",
            "https://www.github.com/cubickem/image-classification-xmltools/blob/master/data/\n",
            "images\"\n",
            "Deep LSTM Networks for Speech Recognition: Improving On-Model Learning\n",
            "\"In the speech recognition task, the key to success lies in the\n",
            "model selection algorithms. Currently the state space models are\n",
            "developed and analyzed in a way that allows training with high\n",
            "rate and low quality. In contrast, the state space models are very\n",
            "reliable in their representations of low level language with high level\n",
            "knowledge in the latent feature space. In this paper, we propose a\n",
            "model selection algorithm that utilizes deep LSTM networks to build a deep\n",
            "framework. In this deep framework, a supervised learning and deep\n",
            "generalization framework is used to construct a training set of\n",
            "deep neural network models from the latent feature space. In this\n",
            "paper, we describe the approach to train deep, classifying deep LSTM\n",
            "neural networks. In addition, we describe three different kinds of\n",
            "deep recurrent networks that we propose in the following two parts. In\n",
            "the first part, our approach is combined with the deep recurrent networks in a\n",
            "way that enables it to learn model for high resolution, high-level\n",
            "knowledge in the latent space and high-level language. The second part\n",
            "proposes that different types of recurrent networks are learned and\n",
            "trained from the latent feature space. We describe a comparison between\n",
            "our approach and existing methods for both low and high resolution feature\n",
            "models,\"\n",
            "Recurrent Neural Network Modeling\n",
            "\n",
            "[610 | 1086.96] loss=2.80 avg=2.98\n",
            "[620 | 1103.29] loss=2.77 avg=2.98\n",
            "[630 | 1119.61] loss=2.84 avg=2.98\n",
            "[640 | 1135.94] loss=3.35 avg=2.98\n",
            "[650 | 1152.30] loss=2.79 avg=2.98\n",
            "[660 | 1168.65] loss=3.29 avg=2.99\n",
            "[670 | 1185.03] loss=2.89 avg=2.99\n",
            "[680 | 1201.40] loss=2.82 avg=2.98\n",
            "[690 | 1217.76] loss=2.91 avg=2.98\n",
            "[700 | 1234.13] loss=3.13 avg=2.98\n",
            "[710 | 1250.51] loss=2.90 avg=2.98\n",
            "[720 | 1266.89] loss=2.84 avg=2.98\n",
            "[730 | 1283.28] loss=2.96 avg=2.98\n",
            "[740 | 1299.65] loss=2.98 avg=2.98\n",
            "[750 | 1316.03] loss=2.98 avg=2.98\n",
            "[760 | 1332.42] loss=2.78 avg=2.98\n",
            "[770 | 1348.81] loss=3.11 avg=2.98\n",
            "[780 | 1365.20] loss=2.73 avg=2.97\n",
            "[790 | 1381.58] loss=2.77 avg=2.97\n",
            "[800 | 1397.96] loss=3.11 avg=2.97\n",
            "======== SAMPLE 1 ========\n",
            "C-POSS (which refers to the problem-solving accuracy) can be very high. However, in our\n",
            "study the quality of the proposed algorithm depends on the input\n",
            "classification method chosen. In order to improve the quality of\n",
            "the proposed algorithm, we consider two methods : (1) a novel\n",
            "distributed training set of multiple independent training datasets, for\n",
            "which each dataset is a mixture of the other samples; (2) a novel\n",
            "multiple-layer perceptron (MLP) model which is trained on each dataset in a\n",
            "different manner, as a separate entity, and where the input is a continuous\n",
            "dictionary. A MLP model, as well as a multi-layer perceptron, are\n",
            "employed by the MLP and the MLP model are considered as the input for\n",
            "the MLP model so that both the dataset and the MLP model are in equal\n",
            "distinction. The MLP model is also used to solve the class-specific\n",
            "problems of the class-related classes. A novel MLP model\n",
            "allows the proposed algorithm to be used in a class-specific class\n",
            "problem in the MLP model and the MLP model also contributes to a class\n",
            "specific problem in the MLP model. In the experiments, the proposed MLP\n",
            "model has been used to solve the class-specific class-problems in\n",
            "the MLP model and in two different classifications-the class-problems of the\n",
            "class-related classes and the class-problems of the classes-with a\n",
            "correctly identified classification error from all the class-specific classes,\n",
            "and is applied to the class-related problems of the class-based groups.\n",
            "Experiments have been performed to demonstrate the accuracy of the proposed\n",
            "multi-layer perceptron in a class-based class problem of the class-based\n",
            "groups, and the accuracy of the proposed MLP model in a class-based class\n",
            "problem of the class-modeling groups. The experimental results show that\n",
            "this approach is very useful for class-specific problems.\"\n",
            "Fast Sparse Network Learning on a Small Set of Data\n",
            "\"Recently deep architecture has been increasingly used for training a deep\n",
            "network. However, the amount of information is not yet sufficient\n",
            "to train a network that can tackle challenging network problems with\n",
            "low-sensitivity memory load. We consider the problem of building a large\n",
            "network capable of deep learning without a lot of information, by\n",
            "associating data with an external neural network instead of a\n",
            "local neural network. In this paper we are interested in the problem of\n",
            "installing an external network into a large deep network without any\n",
            "data associated with it. We propose two new approaches to train\n",
            "an external network. The first approach will be based on an\n",
            "independent method that learns to associate data with an external\n",
            "neural network. The second method, called the Sparse network\n",
            "learning (SPN), is much more flexible. SPN will have more information to\n",
            "facilitate data-sharing. SPN can be learned in parallel on a small set\n",
            "of data. We make three principal contributions: (1) we show that for a\n",
            "network trained with the proposed SPN, the amount of information is\n",
            "unnecessary because it only needs to have limited (1-2) information about the\n",
            "relevant data-in each data-pair in the training set. Moreover, we\n",
            "use a spatial information-dictionary as a learning scheme to facilitate\n",
            "data-sharing and training. (2) Using the spatial information-dictionary as an\n",
            "information-storage mechanism, SPN allows the training of an external\n",
            "neural network, by which all the data associated with its training\n",
            "is learned in parallel. The results shows that the proposed SPN can overcome\n",
            "a problem of insufficient information about the relevant data-in a way that has\n",
            "previously been proven, in many other problems. Our proposed SPN can be used in\n",
            "a wide range of network architectures. Finally, we study a simple\n",
            "network architecture and show its performance in a data-sharing task.\"\n",
            "\"An Analysis and Evaluation of Automatic Classification for\n",
            "  Large-Scale Network Classification: A Preliminary Report\"\n",
            "\"Recently, deep networks in the form of deep nets have shown\n",
            "phenomenal results. Nevertheless, the classification of a large-scale\n",
            "large-scale network network has not been considered much since the introduction of the\n",
            "algorithms. However, several existing approaches were designed in the context\n",
            "of network classification, but their performance has not been evaluated in the\n",
            "current context. Most of the work on network classification works in the\n",
            "training domain while the classification domain is still more focused. One could\n",
            "consider the training domain as one step forward and the classification\n",
            "as one step in. The classification domain is an important step of the training\n",
            "domain, and there is a lack of knowledge and understanding in the deep network\n",
            "domain. A new training domain is introduced where the classification is\n",
            "still a step further\n",
            "\n",
            "[810 | 1436.59] loss=2.90 avg=2.97\n",
            "[820 | 1452.89] loss=2.87 avg=2.97\n",
            "[830 | 1469.26] loss=2.94 avg=2.97\n",
            "[840 | 1485.65] loss=3.01 avg=2.97\n",
            "[850 | 1502.07] loss=2.82 avg=2.97\n",
            "[860 | 1518.50] loss=2.98 avg=2.97\n",
            "[870 | 1534.89] loss=2.75 avg=2.96\n",
            "[880 | 1551.27] loss=2.37 avg=2.95\n",
            "[890 | 1567.62] loss=3.01 avg=2.95\n",
            "[900 | 1584.00] loss=2.80 avg=2.95\n",
            "[910 | 1600.35] loss=2.86 avg=2.95\n",
            "[920 | 1616.68] loss=2.98 avg=2.95\n",
            "[930 | 1633.01] loss=2.67 avg=2.95\n",
            "[940 | 1649.34] loss=2.98 avg=2.95\n",
            "[950 | 1665.67] loss=2.69 avg=2.94\n",
            "[960 | 1682.00] loss=2.63 avg=2.94\n",
            "[970 | 1698.36] loss=2.55 avg=2.93\n",
            "[980 | 1714.71] loss=3.07 avg=2.93\n",
            "[990 | 1731.09] loss=2.89 avg=2.93\n",
            "[1000 | 1747.46] loss=2.97 avg=2.93\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmz93eLszVXM",
        "colab_type": "code",
        "outputId": "1270e6d2-99f0-465a-f95a-5cfec3c318b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1258
        }
      },
      "source": [
        "gpt2.generate(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "high-dimensional,\n",
            "deep representations with low computational complexity for the task of\n",
            "image segmentation. We propose a maximum-likelihood minimum-sample (MOMP) approach\n",
            "for image segmentation, based on a new nonparametric model, based on an\n",
            "adaptive framework for optimization. The proposed model is trained on\n",
            "high-dimensional datasets and analyzed for each sample to estimate the\n",
            "final segmentation error. Our approach is tested on both synthetic and\n",
            "real world images and shows promising results.\"\n",
            "\"A Multi-Level Knowledge-Based Approach Towards Image Segmentation and\n",
            "  Visualization\"\n",
            "\"There is a growing interest in image segmentation and visualization,\n",
            "especially for large-scale images, for which different data is available\n",
            "and used for different tasks. In particular, segmentation is a vital part of\n",
            "image search which enables to perform comprehensive image search. In this paper\n",
            "we design a multi-level knowledge-based approach, based on the\n",
            "MultiSelective MultiSelective (MTM) knowledge base, for the segmentation of multiple\n",
            "images. We use only the images for the selected task and perform a\n",
            "learning-based learning model, based on the MultiSelective MultiSelective\n",
            "(MSM) strategy. We compare our approach to two existing multi-level\n",
            "segmentation algorithms: the MultiSelective MultiSelective (MMS) method and\n",
            "the MultiSelective MultiSelective (MMS) algorithm. Our method runs at a\n",
            "precision of 2.0, which is comparable to the best segmentation algorithms for\n",
            "state-of-the-art multi-level segmentation. We evaluate our method on the\n",
            "segmentation of two image datasets: a 1-D image dataset of\n",
            "large-scale image and a 2-D image dataset of large-scale texture. Our\n",
            "method achieves an average classification accuracy of 79.5 percent,\n",
            "over five times better accuracy than the current state-of-the-art.\"\n",
            "\"Visualizing and Learning the Relative Position of Structured Objects from\n",
            "  Multiple Views\"\n",
            "\"Structured Object Detection (SOD) is a popular and popular\n",
            "algorithm for image-based object detection. The SOD method was\n",
            "solved by the method of Euclidean distance estimation. Similar\n",
            "to SOD, the Euclidean distance is used to estimate the relative position of\n",
            "structured objects. However, in SOD, the method of Euclidean distance estimation\n",
            "is used instead of the Euclidean distance estimation. This has several\n",
            "negative effects on the accuracy of the sOD algorithm. We propose to\n",
            "visualize the relative positions of the object segments using a\n",
            "multi-level SOD model. We show that our method is effective for both smooth\n",
            "and polygonal images. We also propose to use the relative positions as\n",
            "cascaded feature vectors to learn the segmentation prediction structure\n",
            "of the image. The proposed relative positions, the visualized position of\n",
            "structured objects, and the predicted segmentation structure are then\n",
            "used for image segmentation using the Multi-Level SOD model.\"\n",
            "Towards High-Dimensional Data Analysis Using Wavelet and\n",
            "  Graph-Based Models\n",
            "\"In this paper, we propose an end-to-end deep neural network based\n",
            "network architecture for high-dimensional data analysis. The network is\n",
            "built using wavelet and graph-based models while learning a subset of\n",
            "the data features that are meaningful in the experience space. The\n",
            "performance of our model is evaluated on two datasets. In the first, we\n",
            "show that our model learns the structure of the data features and\n",
            "transforms them into a graph-based network model. In the second, a\n",
            "tower of data with weak features is used to train an efficient\n",
            "deep neural network model. To significantly improve the performance, we\n",
            "find that the model can be trained on a fraction of the data features\n",
            "and the network model is able to learn the structure of the data. We\n",
            "also show that our model is able to handle the low-dimensional\n",
            "variations of high-dimensional data in the real-world.\"\n",
            "Transforming Deep Neural Networks\n",
            "\"We introduce Transforming Deep Neural Networks, a new deep learning\n",
            "framework for deep learning for convolutional neural networks. The\n",
            "framework is based on the observation that deep neural networks\n",
            "can encode a wide range of partial transformations on multiple\n",
            "sub-networks. We show that transforming deep neural networks is a\n",
            "powerful tool for learning a large number of transformations on\n",
            "multiple sub-networks. We illustrate our approach by performing\n",
            "a series of transformation experiments on a series of deep neural networks. We\n",
            "show that the state-of-the-art deep learning approaches are unable to\n",
            "transform deep neural networks to a more high-dimensional model. Furthermore,\n",
            "we show that transforming deep neural networks can transform the\n",
            "state-of-the-art deep learning methods to a more high-dimensional model.\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37YdR2n10kYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yoknpSc0vmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=1000,\n",
        "                      batch_size=20\n",
        "                      )\n",
        "\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUX1ODtV9bFz",
        "colab_type": "code",
        "outputId": "f0d45407-6fbf-4fbd-b7f0-2387f174e5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1700
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LSTM\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM\n",
            "\"LSTM is a generalization of the popular LSTM model, which consists in\n",
            "integrating the original LSTM model with a large amount of LSTM-specific features\n",
            "to minimize the dimensionality of the data.\n",
            "  Since its inception, the LSTM model has helped to solve a variety of\n",
            "generalization problems. Recently, the LSTM model has been widely used in a variety of\n",
            "adversarial applications. However, it is often neglected in the practical\n",
            "managed LSTM environments. This paper proposes a simple approach to\n",
            "introduce the LSTM model to managed LSTM environments. The LSTM\n",
            "model is introduced in two steps. First, a new LSTM model is developed\n",
            "by combining the LSTM model with the LSTM model. Second, a new\n",
            "standard LSTM model is developed by combining the LSTM model with the\n",
            "new LSTM model. The proposed approach is applied to several real-world\n",
            "datasets and validated on a variety of publicly available LSTM datasets.\"\n",
            "Extraction from unbalanced data with a probabilistic model\n",
            "\"In this paper, we propose a probabilistic model\n",
            "====================\n",
            "\n",
            "LSTM model. The results demonstrate that\n",
            "such models are able to significantly outperform state-of-the-art automatic\n",
            "learning methods in terms of performance on each classification task.\"\n",
            "\"Semantic Regularization for Large-Scale Object Detection Using Linear\n",
            "  Programming\"\n",
            "\"We introduce a new semantic regularizer named Semantic Regularizer (SP) (Lip\n",
            "Siew et al., 2017a) that can be used to exploit the semantic similarity\n",
            "between two objects in a stream of images. We show that this semantic\n",
            "regularizer is able to learn the semantic similarity between two images and\n",
            "produce more accurate object detection, as compared to an existing semantic\n",
            "regularizer. Moreover, we show that our semantic regularizer can be used to\n",
            "solve network-based contextual classification problems, which has been applied to\n",
            "deep neural networks. We demonstrate that our SP model can be trained on a wide\n",
            "variety of datasets, including MNIST, CIFAR-10, and TIFF, and can be\n",
            "successfully applied to multiple object detection applications, including semantic\n",
            "detection and semantic segmentation.\"\n",
            "\"Semantic Regularization for Large-Scale Object Detection Using Linear\n",
            "  Programming\"\n",
            "\"We introduce a new semantic\n",
            "====================\n",
            "\n",
            "LSTM - Learning a Batch-wise Semantic Representation\n",
            "\"We propose a new approach for learning semantic representations from\n",
            "large-scale data sets with the use of convolutional neural networks. Our\n",
            "approach computes a semantic representation of a data set and builds a semantic\n",
            "representation model that can capture the semantic meaning of a data set. The\n",
            "proposed approach provides semantic descriptions of data sets. We experiment\n",
            "on a number of diverse datasets including real world data from the Internet.\n",
            "Experimental results on datasets of the Internet, Nature, and Stanford\n",
            "University demonstrate the effectiveness of the proposed method.\"\n",
            "Deep Annotation in 3D Image Processing\n",
            "\"This paper proposes a novel deep neural network for the annotation of 3D\n",
            "3D image processing. The proposed deep neural network is capable of both\n",
            "high-level semantic information and semantic information from coarse visual\n",
            "representations. Moreover, it is able to perform semantic\n",
            "annotations on a relatively small set of images. The proposed deep network is\n",
            "supervised by a feature-driven learning framework and its supervised learning\n",
            "model is capable of creating semantic annotations. The proposed prototype\n",
            "model achieves competitive results over state-of-the-art deep neural network\n",
            "for the task\n",
            "====================\n",
            "\n",
            "LSTM did not significantly improve on the\n",
            "non-linear trait learning tasks on the MEG-500. However, the\n",
            "non-linear tasks on the MEG-500 were much more challenging than those on\n",
            "the MEG-500. Then, the performance of the dynamics models on the MEG-500\n",
            "were much better than those on the MEG-500. Finally, we used the dynamics models\n",
            "on the MEG-1000 to validate the dynamics model with respect to the MEG-500.\"\n",
            "\"Efficient Deep Learning for Understanding Robotic Hand Gesture Recognition\n",
            "  by Robustly Compressing the Evidence\"\n",
            "\"Hand gesture recognition is an important factor in grasping and grasping\n",
            "hand and object recognition systems. The aim of this paper is to design a\n",
            "robustly compressing the evidence of gestures and hand gesture, and a\n",
            "robustly learning the gestures and hand gesture from the input. We\n",
            "propose to learn gesture gestures from the input. The proposed method\n",
            "is based on a robustly learning gesture gestures from the input and\n",
            "compressing the evidence, to train a robustly learner. The model is\n",
            "developed by using a Convolutional Neural Network (CNN) architecture. The\n",
            "====================\n",
            "\n",
            "LSTM with a high likelihood\n",
            "expression loss model which is aligned to the MNIST and Microsoft\n",
            "segmentation datasets. We demonstrate the effectiveness of our model on\n",
            "two benchmark datasets comparing with the state-of-the-art methods. We\n",
            "evaluate our model in a wide range of applications, illustrating the\n",
            "benefits of our model on a diverse set of datasets.\"\n",
            "\"A Supervised Learning Approach for Discriminative Image\n",
            "  Captioning\"\n",
            "\"In this paper, we address the task of image captioning. We\n",
            "introduce a new supervised learning algorithm based on the Supervised\n",
            "Learning (SRL) framework, which is capable of inferring the semantic\n",
            "information of the image captioning task. Supervised Learning (SRL)\n",
            "provides a powerful framework for the task of image captioning as it\n",
            "provides a means of semantically annotating images. In our experiments,\n",
            "supervised learning reliably deduces the semantic information of more than\n",
            "90% of the annotated images. The key contribution of our work is that we\n",
            "learn a new approach for annotating the annotated images that uses a\n",
            "supervised learning framework and also helps to improve the performance of the\n",
            "reliable SRL model\n",
            "====================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-YTBn1OEDGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MloyQbpENVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp *.txt models checkpoint drive/gpt2project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L73B__98EW98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir drive/'My Drive/opengpt2project'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZavRhBh6EaQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp *.txt models checkpoint drive/'My Drive/opengpt2project'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTUuT_MuEy-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Hq8avtqlEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}